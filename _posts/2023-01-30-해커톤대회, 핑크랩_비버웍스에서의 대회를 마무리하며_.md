---
title : 해커톤대회, 핑크랩_비버웍스에서의 대회를 마무리하며~
date : 2023-01-30 09:15:00 +09:00
categories : [202301해커톤]
tags : [비버웍스, 핑크랩, 해커톤, NLP] 
---

# 해커톤

---

마라톤 + 해커 정도의 의미로, IT 기술계의 마라톤 같은 느낌이다.

마라톤에도 여러 종류가 있듯이 해커톤도 마찬가지다.

프로 레벨들이 모여서 기록을 위해 달리는 마라톤이 있고, 아마추어 레벨이 모여서 완주를 위해 달리거나 건강을 위해서 걷는 마라톤도 있듯이 말이다.

개인적으로 비버웍스에서의 해커톤은 **아마추어 레벨이 연습하기 위해 완주하는** 정도의 느낌이었다.


## 목표

---

- 상품명의 표준화


굉장히 심플하고 여러 아이디어가 나올 수 있는 목표였다고 생각한다.

NLP 문제라서 그러한 방향의 접근은 기본이었다.

### 그러나 이 목표의 단순함이 아쉬웠다.

정확히 이 대회의 목표가 어떤 것인지에 대해서 애매모호했다는 점이 바로 그러하다.

일반적으로 NLP에서의 표준화라고 하면 전처리 과정을 의미하는데, 이 전처리 과정은 워드 임베딩 전의 데이터 정제 작업에 해당한다.

![NLP Machine Learning Workflow | kite_mo](https://wikidocs.net/images/page/31947/%EB%A8%B8%EC%8B%A0_%EB%9F%AC%EB%8B%9D_%EC%9B%8C%ED%81%AC%ED%94%8C%EB%A1%9C%EC%9A%B0.PNG)

결국 DL 을 사용해도 이 과정은 비슷하게 따라가는데, "전처리" 에 해당하는 표준화가 목적인가?

그렇다면 이 표준화라는 것은 Target값이 될 수 없는 구조다.

**딸기요거트스무디** 라는 단어가 있다면

**딸기 요거트 스무디** 라는 단어가 특정 표준화 규칙(대회에서 기업이 요구한 규칙들)을 적용했을 때의 결과다.


이러한 방식의 규칙을 정한 표준화는 걸러내지 않는 핵심 단어가 새로 나올 때마다 정답으로 인식되는 표준화 결과 또한 새롭게 등장한다.

### 예시

이전까지의 데이터셋에서는 

계란라면 -> 계란 라면

맛좋은계란라면 -> 계란 라면


(이 예시는 표준화 라벨링을 Target값으로 정했을 때 가능한 좋게 생각하기 위한 가정이다)

(실제로 주최측에서 준 표준화 이후의 결과 수준은 맛좋은계란라면을 맛좋은 계란 라면 으로 표준화 하는 수준이었다.)

### 문제점

저 정도의 입력값(맛좋은계란라면) 과 출력값(계란 라면)으로 이루어진 데이터셋이 있다고 생각해보자

이를 바탕으로 훈련시킨 모델은 이후의 테스트 데이터에서는 

- "계란참깨라면" 을 만나게 되고, 

- 이에 대한 올바른 표준화 규칙은 "계란 참깨 라면" 이 되겠지만, 모델은 이를 반영하지 못한다.

만약 이전에 Target에 포함되지 않은 표준화 결과가 존재한다면

**OOV 문제와 비슷한 현상이 발생하는데 이에 대한 처리를 "알수없음" 정도로 넘기거나 "계란참깨라면" 을 "계란 라면" 으로 예측하면서 중요한 특성을 없애게 된다.**

결국 이 "표준화 ML 모델" 이라는 것의 정확도는 올라갈지 몰라도 실제로 모델은 GIGO의 상황에 들어가게 된다.

## Garbage In Garbage Out(GIGO)

쓰레기를 넣으면 쓰레기가 나온다는 의미로 일반적으로 코드 내 함수에 통용되는 말이다.

이는 ML 분야에서도 마찬가지이며, 더 악질인 점은 정확도와 같은 평가 지표로 구분할 수 없다는 점이다.

결국 이에 대한 주장을 하기 위해서는 수 만개가 넘는 데이터를 EDA하면서 "인간 기준" 에서 틀렸다고 판단되는 label이 어떤 형태인지, 어느 정도의 비율을 가졌는지 파악하고 제시해야 한다.

게다가, 이 문제의 경우에는 Input 에 해당하는 데이터가 쓰레기인게 아니라, Output에 해당하는 label이 쓰레기인 상황이라서 문제는 더욱 심화된다.

ML의 모든 기준점은 label에서 나오며, 어느정도의 노이즈에 대한 학습이 가능한 것도 근본적으로 label이 제대로 부여되어 있다는 상황을 전제한 것이다.

### 예시

외계인 초등학생 시험을 예로 들자면,  1ㅇ1 = ? 이라는 아주 쉬운 문제가 출시되었는데

정답지에 실수로 선생님이 3이라고 넣어놨다. ( 1 ㅇ 1 = 2가 정답이다. )

학생들은 1 ㅇ 1 = 3이라고 인식하게 되었다.

그리고, 1 ㅇ 2 = 3 이라고 배웠다.

이들은 1 ㅇ 1 와 1 ㅇ 2 는 같다고 인식한다

> 여기까지만 봐도 문제가 있다는 것을 알 수 있지만, 더 나아가면 이 문제는 더욱 심화된다.

그렇게 1 ㅇ 1 = 1 ㅇ 2 라는 학생들은 이후에

3 ㅁ 1 = 2 라고 배우게 된다.

이들에게 3 = 1 ㅇ 1 이거나 1 ㅇ 2 이므로

1 ㅇ 1 ㅁ 1 혹은 1 ㅇ 2 ㅁ 1 = 2 가 된다.

하나만 틀렸는데도, 계속해서 관련된 모든 것을 틀리게 될 수 있다는 것이다.

1 ㅇ 1은 1+1 이고 정답은 2였다는 것을 생각하면 단순하게 잘못된 label이 발생시킬 수 있는 문제는 계속해서 확장될 수 있는 가능성이 있다.


### 대처방안?

- 일반적으로 적당한 cardinality 를 가진 category에 대한 다중분류 문제라면 이러한 잘못 분류된 데이터를 어느정도 파악할 수 있다.

-  하지만 "표준화" 라는 문제는 일반적인 상황과 다르다.


## 표준화를 예측하는 모델이 가진 문제

---
표준화 전

- 거기 어뎁니꺼

표준화 이후

- 거기 어디입니까

위의 사례만 봐도, **표준화는 "특성을 대부분 유지한 상태로 이해하기 편하게 하나의 형태로 만드는 것" 정도**로 이해할 수 있다.

이 말은 곧, 입력값인 X와

출력값(표준화 이후 결과)인 Y가 거의 같다는 것을 의미한다.

일반적인 사람의 논리 구조라면 Y = X + X 정도의 유사한 구조가 보인다면

X = 1 -> Y = 1 + 1
X = 2 -> Y = 2 + 2
X = 3 -> Y = 3 + 3

까지만 학습해도 X = 4 -> Y = 4 + 4 라는 것을 인식하게 된다.

이는 ML에서도 가능한 일일까?

## 분류의 경우

적어도 분류 문제에서는 100% 문제가 일어난다.

X = 1 -> Y = 2 라고 인식하는게 분류 문제인데

X = 2 -> Y = 4
X = 3 -> Y = 6

처럼 학습하게 된다.

이 경우, X = 4 -> Y = 2, 4, 6 중 하나라고 인식하고 그에 대한 확률을 계산하게 될 것이다.

마치 시험장에서 5지선다 문제에 마주했을 때 전혀 모르겠으면 그 중 하나를 찍는 여러가지 방법을 고민하는 것처럼 말이다.

하지만 우리는 "표준화" 가 가진 특성이 Y는 X와 비슷하다는 것을 인지하고 있다.

결국 X = 1~3의 데이터셋을 통해서 정확도가 0.95 이상이 나온 모델을 구현했지만

X = 4 -> Y = 2 가 나오게 된다면 모델을 믿을 수 없는 상황이 오게 될 것이다.

X = 4 일때, Y = 8 이 나와야 하지 않는가? 


### 왜 이런 일이?


왜 이런 당연한 부분을 파악하지 못하는 일이 일어난 것일까?

바로 이는 사람의 직관이 가진 한계점에 있다.

![월드컵 직관한 악뮤 수현과 함께 포착된 남자 배우 '두 사람' | 위키트리](https://cdnweb01.wikitree.co.kr/webdata/editor/202212/07/img_20221207164325_955e6184.webp)

> 여기에 몇 명의 사람이 있는가?
>  3명?
>  수가 많아질수록 바로 파악할 수 없고, 파악한다고 해도 뇌에서 활용하지 못한다.

위의 데이터셋은 3개뿐이라 단순하고, 관계도 명확한 선형성을 가정했기에 아주 당연하게 틀렸다는 사실을 생각해볼 수 있다.


하지만, ML을 적용하는 문제는 보통 데이터셋이 수천개 이상이며 수십 수백만이 넘는 경우도 있다

가장 기본적인 분류 / 회귀 문제에 대한 기준점조차도 헷갈릴 수 있는 것이다.


### **규칙성에 대한 착각**

- 분류와 회귀를 가르는 가장 핵심적인 이유는 무엇일까?

- label이 categorical data면 분류고 numerical data면 회귀인가?

그렇게 간단한 문제라면 누구도 실수하지 않을 것이다.

핵심은 데이터가 아니며, 모델을 사용하여 예측하려는 문제와 그 문제가 가진 규칙성에 있다.

- Categorical data는 세상의 모든 것을 그 범주로 분류하겠다는 선언과 같다.

- Numerical data는 세상의 모든 것을 데이터에 반영하진 못했지만, 숫자의 어느 영역에 있을 것이라는 가정을 한 것과 같다.

크게 생각하면 Numerical data를 label로 하여 회귀 문제로 접근할 경우 무한대의 범주로 다중분류를 한다고 볼 수도 있다.

결국 위의 예시는 회귀 문제로 접근하면 당연하게 문제점이 해결된다는 것처럼 이 표준화의 문제 또한 그렇게 접근해야 할 수 있다.


## NLP를 회귀 문제로 접근

---

- 솔직하게 아직 다뤄본 영역이 아니라서 어떤 결과가 나올지 알 수 없다.

- 향후에 비슷한 상황을 다뤄보게 되면 이쪽 방향으로 접근해보는 것도 좋을 것이라는 생각이 든다.


## 느끼고, 배웠다

- ML 통한 문제 해결을 왜 하는가?

그 각각의 이유가 중요하다고 보았다.

학술적인 필요도 있겠지만 아마 대부분은 비즈니스적인 필요에 대한 해결 방안을 찾다보니 도달하게 된 결과라고 생각한다.

필요한 사람에게

필요한 서비스를.

그게 앞으로 데이터 직군으로의 마음가짐이 되어야 하지 않을까 생각해본다.



### 다들 훌륭했다.

여러 발표를 들어보면서 생각하지 못한 부분도 알게 되고, 설득력있는 접근법, 요소들을 발견하는 재미도 있었다.

특히나, 경력자나 회사의 대표가 보는 시선에서 포인트가 어떤 점이 될 수 있는지 생각해볼 수 있다는 점이 좋았다.




## 다음에도 해커톤

---

- 열심히 했고, 재밌었다.

- 아쉽지만 솔직히 이 정도로 즐거우면서 화가 나기도 해본 경험은 처음이었다.

- 고생해준 팀원들에게 고맙고, 즐거운 시간을 선사해준 대회 주최측, 회사측에게도 감사하다고 말하고 싶다.

- 다음에도 할 것이냐? 기회와 시간이 있다면 반드시 할 것이다.

- 향후에 이 부분은 반드시 생각하고 행동해야 한다는 몇몇 포인트가 있었다.

---
### 문제를 제기한 의사결정자에 대해 파악하자

향후 해커톤 대회나 비슷한 것을 준비한다면 반드시 회사측의 요구조건이나 니즈를 지속적으로 물어보고, 정확히 파악하는 과정을 가져야할 것 같다.

솔직하게 이번 대회에서 위의 표준화를 ML 모델로 접근하는 방법에 대한 가정이 틀렸다고 생각하지만, 이를 증명하고 다른 방향을 찾는 과정은 힘들고 시간이 많이 든다.

전반적으로 아직 배우는 입장이 모인 팀의 수준에서는 다소 너무 어려운 방향성이었던 것 같다.

무엇보다도 결국 의사결정자가 원한 것은 주어진 데이터셋을 믿고 활용하는 것이었다.

데이터셋 자체에 대한 문제점이나, 구조적 결함이 중요하진 않다고 가정하는 점 또한 팀장으로서 알아봤어야 했을지도 모른다.

---

### 팀은 비효율적인게 효율적이다

팀원과의 협업 과정에서도 생각해볼 부분이 많았고, 팀장으로서 다소 부족한 점이 많았다고 생각했다.

특히나 핵심 작업과정은 다소 비효율적이라도 다 같이 작업해서 서로의 이해도를 높이는게 좋다고 느꼈다.

화면 공유를 통해서 모여서 서로 코딩(모서코) 를 하는게 나름의 재미도 있고 훨씬 이해도가 높아질 것 같았지만 해보지 못해서 아쉽다.

---

### 발표, 그리고 또 발표 

학술적인 대회라면 조금 다르겠지만, 결국 비즈니스적 문제라면 활용 가능성과 결과가 더 중요하게 된다.

이런 시야를 제시하고, 논리를 이야기하는 발표가 이런 대회에서 얼마나 중요한지를 아주 잘 깨달았다.

결국 문제점이 있다고 한들, 의사결정자가 원하는 것은 이것을 통해 해결할 수도 있을 결과다.

문제가 발생하면, 또 그건 다른 해결책을 찾는 것이다.

(이런 접근법이 정답은 아니나, 그렇다고 확실하게 틀렸다고 말할 수도 없다)

---

### 기본만 해도 평균이 아니다

정말 재밌는 점인데, ML 분야 자체가 워낙 복잡한 과정과 이론을 적용시키다보니 이 기본적인 것들만 제대로 해도 강력한 성능이 나온다.

> **특별한게 없어도 특별하다.**

ML 의 매력은 바로 이런 것이 아닐까?











 
