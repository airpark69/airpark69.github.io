---
title : 해커톤대회, 다중분류에서의 불균형은 치명적
date : 2022-12-30 21:35:00 +09:00
categories : [202301해커톤]
tags : [비버웍스, 해커톤, NLP] 
---


# 데이터 수집은 끝?
---

네이버 API와 크롤링을 통한 수집으로 약 24만개의 학습 데이터를 얻었다.


## 데이터 전처리

- 중복값 제거
- 결측치 처리
- 불용어 제거
-> 이 경우, 특수문자만 제거했다.



## fastText 지도 학습

- fastText의 강점을 활용
- 빠르다
- 학습되지 않은 단어도 처리가 가능하다
- 간단하게 활용 가능



### 결과

```python
(('__label__과자/떡/베이커리',), array([0.52032429]))
```

"찜닭" 을 예측한 결과

훈련 , 평가, 테스트 데이터셋을 0.65 0.15 0.2로 나눴을 때

테스트 데이터셋에서의 정확도는 0.86 정도



##  데이터 불균형!

---
- EDA 결과, 카테고리의 범주 불균형이 어느정도 있는 것으로 판단되었다.

```
커피/차류 0.116126
건강식품 0.109631 
냉동/간편조리식품 0.076334 
간편조리식품 0.072448 
과자/베이커리 0.071926 
음료 0.052801 
수산물 0.052283 
생수/음료 0.049265 
과자/떡/베이커리 0.045218
조미료 0.042188 
밀키트 0.038756 
축산물 0.036616 
다이어트식품 0.029626 
농산물 0.029254 
반찬 0.027989 
가루/분말류 0.027722 
장류 0.024933 
유가공품 0.020713 
통조림/캔 0.019639 
전통주 0.017931 
소스/드레싱 0.008001 
라면/면류 0.007242 
잼/시럽 0.007084 
주방용품 0.004963 
김치 0.004310 
제과/제빵재료 0.004028 
식용유/오일 0.002973
```
![1230_1](https://user-images.githubusercontent.com/50907018/210077866-f1c711b9-582d-4f93-95b6-eeb713228af6.png)


-> 이러한 불균형이 가중치를 업데이트할 때 오차를 크게 만들었으며 모델의 성능을 저하한다고 보았다.


## 해결책

따라서 오버샘플링과 언더샘플링 둘 중 하나를 선택해야 한다.

이 경우, 오버샘플링과 언더샘플링을 섞어서 적절한 중간지점까지 데이터를 수집하기로 하였다.

데이터가 적은 범주의 경우 데이터를 채워넣고, 데이터가 많은 범주는 데이터를 줄이는 과정을 거칠 것이다.



## 협업 과정에서의 시행착오

---

![조별과제](https://user-images.githubusercontent.com/50907018/210079534-3edd1bd3-9a6e-4aef-8262-c71a83346d6a.jpg)

> 이런 일이 일어나면 안된다.

- 팀 단위의 협업을 진행 중

- 이에 따라 데이터 전처리 과정에서도 서로 간의 활발한 커뮤니케이션이 필요
 
- 특정 범주가 서로간의 의사소통 불일치로 인해서 너무 세분화된 것을 확인했다.

협업 시에는 항상 과정을 공유하고 백업 파일을 각 단계마다 정확히 네이밍해서 보관할 필요가 있다고 보았다.



## 향후 방향성

- 데이터 수집과 전처리를 계속 진행
-> 전처리 과정에서 기준점을 잡고 향후 대회에서 적용하는 것을 목표
-> 대회는 짧은 시간이 주어지기 때문

- 일정 기준으로 성능이 나올 경우, 이후에는 실시간으로 데이터를 처리하는 서비스에 집중할 예정

- 비지도학습을 통해, 특정 키워드에 대한 추천 시스템 같은 부분도 구현하면 좋겠다고 생각 중 


